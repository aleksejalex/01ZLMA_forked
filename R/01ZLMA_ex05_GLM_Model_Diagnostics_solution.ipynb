{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francji1/01ZLMA/blob/main/R/01ZLMA_ex05_GLM_Model_Diagnostics_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-i6MbNFm4Zt"
      },
      "source": [
        "# 01ZLMA - Solution of HW from Exercise 05\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYmgrHoBFw_q"
      },
      "source": [
        "### Install and get libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MEm5eAXHWGB"
      },
      "source": [
        "library(tidyverse)\n",
        "library(MASS)\n",
        "library(knitr)\n",
        "\n",
        "install.packages(\"GGally\")\n",
        "library(GGally)\n",
        "\n",
        "#install.packages(\"car\")\n",
        "#library(car)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "K6FZEl9NFw_2"
      },
      "source": [
        "## Residuals reacap\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG_umnicMwuQ"
      },
      "source": [
        "Consider  the GLM from for the observations $Y_1,\\ldots,Y_n$ and assume $a_i(\\phi) = a_i \\phi$, where $a_i>0$ are known for $i=1,\\ldots, n$.\n",
        "\n",
        "\n",
        "\n",
        "From estimation of GLMs as Locally Like Linear Regression by using IRLS we can obtain weights $W$ with  *working responses* and compute *working residuals*.\n",
        "\n",
        "**Working residuals**\n",
        "$$e_i = z_i − \\hat{\\eta_i}$$\n",
        "\n",
        "**Pearson residuals**\n",
        "\n",
        "$$ {r_{i}^{P}\n",
        "=\\frac{y_{i}-\\hat{\\mu}_{i}}{\\sqrt{a_i\\, v(\\hat\\mu_i)}}},\\qquad\n",
        "v(\\mu_i)= b^{\\prime\\prime}(\\theta_i) \\mbox{ for } \\theta_i = \\theta(\\mu_i),\n",
        "$$\n",
        "\n",
        "where $v(\\mu_i)$ is called a variance function and $V[Y_i] = a_i \\phi v(\\mu_i)$.\n",
        "The Pearson residual is the response residual scaled with with the estimated standard deviation for the observation.\n",
        "\n",
        "\n",
        "**Pearson standartized residuals**\n",
        "\n",
        "$$\n",
        "{r_{i}^{PS}\n",
        "=}\\frac{y_{i}-\\hat{\\mu}_{i}}{\\sqrt{\\hat{V}[Y_{i}](1-h_{ii})}}\n",
        "=\\frac{y_{i}-\\hat{\\mu}_{i}}{\\sqrt{a_i \\hat\\phi \\, v(\\hat\\mu_i)(1-h_{ii})}}\n",
        "={\\frac{r_{i}^{P}}{\\sqrt{\\hat\\phi(1-h_{ii})}}},\n",
        "$$\n",
        "\n",
        "**Anscombe residuals**\n",
        "\n",
        "For models, where $a_i(\\phi)=1$ \n",
        "$$\n",
        "{r_{i}^{A}=\\frac{A(y_{i})-A(\\hat{\\mu}_{i})}{\\sqrt{\\hat{V}[A(y_{i})]}}},\\quad i=1,...,n\n",
        "$$\n",
        "where\n",
        "$$\n",
        "A(y)=\\int_{-\\infty}^{y}\\frac{d\\mu}{v^{1/3}(\\mu)}.\n",
        "$$\n",
        "\n",
        "**Deviance residual**\n",
        "\n",
        "The deviance residual for the i’th observation is defined as\n",
        "\n",
        "$$\n",
        "{r_{i}^{D}=\\mbox{sign} (y_{i}-\\hat{\\mu}_{i})\\sqrt{D_{i}}},\\quad i=1,...,n, \n",
        "$$\n",
        "where\n",
        "$$ \n",
        "D=\\sum_{i=1}^{n}(r_{i}^{D})^{2} = \\sum_{i=1}^{n}D_{i}=\n",
        "\\sum_{i=1}^{n}\\frac{2}{a_{i}}\\left[y_{i}(\\tilde{\\theta}_{i}-\n",
        "\\hat{\\theta}_{i})-\\left(b(\\tilde{\\theta}_{i})-b(\\hat{\\theta}_{i})\\right)\\right].\n",
        "$$\n",
        "\n",
        "\n",
        "**Deviance standartized residual**\n",
        "$$\n",
        "{r_{i}^{DS}=\\frac{r_{i}^{D}}{\\sqrt{\\hat\\phi(1-h_{ii})}}},\\quad i=1,...,n,\n",
        "$$\n",
        "\n",
        "The deviance residuals are the generalization of the residuals from the classical linear model. They are constructed using the analogy between the deviance and the RSS."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SkSjX0y4sCcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Type of residuals in R for a fitted glm() `model`:\n",
        "\n",
        "• Pearson residuals $r^P$ : `resid(model, type=\"pearson\")`.\n",
        "\n",
        "• Deviance residuals $r^D$ (default): `resid(model)`\n",
        "\n",
        "• Quantile residuals $r^Q$ from package `library(statmod)`: `qresid(model)` \n",
        "\n",
        "• Partial residuals $u_j$ : `resid(model, type=\"partial\")`.\n",
        "\n",
        "• Working residuals $e$: `resid(model, type=\"working\")`.\n",
        "\n",
        "• Response residuals $(y − \\hat{\\mu})$: `resid(model, type=\"response\")`.\n",
        "\n",
        "• Standardized deviance residuals $r^{DS}$: `rstandard(model)`.\n",
        "\n",
        "• Studentized deviance residuals $r^{DStud}$: `rstudent(model)`.\n"
      ],
      "metadata": {
        "id": "NsXwNmNSsCsU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoU_Xf0FX7fA"
      },
      "source": [
        "Gamma model is necessarily heteroskedastic, because the variance is  proportional to $μ^2$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqiszEwYFw_5"
      },
      "source": [
        "If the evidence shows problems with the systematic component, then the\n",
        "cause may be an incorrect link function, or an incorrect linear predictor (for\n",
        "example, important explanatory variables are missing, or covariates should\n",
        "be transformed), or both.\n",
        "\n",
        "*Working responses* $z_i = \\hat\\eta_i + g^\\prime(\\hat\\mu_i) (y_i-\\hat\\mu_i)$ \n",
        " can be determined from working residuals, obtained by the function `resid(model, type=\"working\")`. \n",
        "\n",
        " We plot Working responses against predicted values of linear predictor $\\hat\\eta_i$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb7wTr9ocb6X"
      },
      "source": [
        "To determine if covariate $x_j$ is included on the incorrect scale, use partial\n",
        "residuals\n",
        "$$ u_j = e_i + \\hat{\\beta}_j x_j.$$\n",
        "In R use function `resid(fit, type=\"partial\")`. \n",
        "\n",
        "Component+Residual (Partial Residual plot, ie. $x_j$ against $j$th partial residuals) can be plotted by function `termplot()` or `crPlots()` from the library `cars`"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Influence  Measures\n",
        "\n",
        "Measures of influence can be computed using the same R functions\n",
        "as for linear regression models:\n",
        "\n",
        "• Cook’s distance D: `cooks.distance(model)`.\n",
        "\n",
        "• dfbetas:  `dfbetas(model)`.\n",
        "\n",
        "• dffits: `dffits(model)`.\n",
        "\n",
        "• Covariance ratio cr: `covratio(model)`.\n",
        "\n",
        "All these measures of influence, together with the leverages $h$, are returned using `influence.measures(model)`."
      ],
      "metadata": {
        "id": "decD_BF0wTBI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gOhYf-ZFw_-"
      },
      "source": [
        "**Cook distance**\n",
        "\n",
        "Let $\\hat\\beta_{(-i)}$ denotes estimation of $\\beta$ computed without observation  $i$. Cook distance for $i$th observation is defined by\n",
        "$$CD_i = \\frac{1}{p} \\left(\\hat\\beta - \\hat\\beta_{(-i)}\\right)^T X^T W^{-1} X \\left(\\hat\\beta - \\hat\\beta_{(-i)}\\right)$$\n",
        "but its computed by \n",
        "$$\n",
        "CD_i = \\frac{1}{p} \\left( r_i^{PS}\\right)^2 \\frac{h_{ii}}{1-h_{ii}} \n",
        "$$\n",
        "and observation is influence if \n",
        "$$\n",
        "CD_i \\ > \\ \\frac{8}{n-2p}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5Nc73VhFxAA"
      },
      "source": [
        "A negligible change again"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "fOCN_fc8FxAA"
      },
      "source": [
        "**Function `influence.measures()`.** \n",
        "\n",
        "We know it from `lm()` and the usage is very similar. It obtain Cooks distance (`cook.d`) and diagonal elemtns of hat matrix (`hat`) and other influence measures."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Your Turn: HW 05\n",
        "\n",
        "Problem 8.6. from the book:\n",
        "\n",
        "\n",
        "The standardized deviance residual $r^{DS}$ is approximately the reduction\n",
        "in the residual deviance when Observation $i$ is omitted from the data. Demonstrate this by R code using the $trees$ data as follows.\n",
        "\n",
        "* Fit the model m_1 as\n",
        "\n",
        "  `data(trees)`\n",
        "   `model_full <- glm( Volume ~ log(Girth) + log(Height),family=Gamma(link=log), data=trees)`\n",
        " Compute the residual deviance, the Pearson estimate of $\\phi$, and the standardized deviance residuals from this model.\n",
        "\n",
        "* Omit Observation 1 from `trees`, and refit the model. Call this model\n",
        "`model_omit_1`.\n",
        "\n",
        "* Compute the difference between the residual deviance for the full model\n",
        "`model_full` and for model `model_omit_1`. Show that this differences divided by the Pearson estimate of $\\phi$ is approximately the standardized\n",
        "deviance residuals squared.\n",
        "\n",
        "* Repeat the above process for every observation $i$. At each iteration, call this model `model_omit_i`. Then, compute the difference between the deviance for the full model `model_full` and for model `model_omit_i`. Show that these differences divided by $\\phi$ are approximately the standardized residuals squared.\n"
      ],
      "metadata": {
        "id": "aBmJtSNrygWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_full <- glm( Volume ~ log(Girth) + log(Height),family=Gamma(link=log), data=trees)\n",
        "summary(model_full)"
      ],
      "metadata": {
        "id": "XWdMo-S6JnBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deviance residuals (default)\n",
        "resid(model_full)"
      ],
      "metadata": {
        "id": "2qWSV_FsKRsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardized deviance residuals\n",
        "rstandard(model_full)"
      ],
      "metadata": {
        "id": "X5fVk1EIKUug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pearsons estiamtes of phi\n",
        "phi_est = summary(model_full)$dispersion\n",
        "phi_est"
      ],
      "metadata": {
        "id": "SV0-10XTKrMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Omitting the first observation\n",
        "trees1 = trees[-1,]\n",
        "\n",
        "model_omit_1 = glm( Volume ~ log(Girth) + log(Height),family=Gamma(link=log), data=trees1)\n",
        "summary(model_omit_1)"
      ],
      "metadata": {
        "id": "i0yQywkBK-d8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Residual deviances\n",
        "# Compute the difference between the residual deviance for the full model model_full and for model model_omit_1. \n",
        "cat(\"Residual deviance of the full model: \", model_full$null.deviance - model_full$deviance, \".\\n\")\n",
        "cat(\"Residual deviance of the model with the first observation omitted: \", model_omit_1$null.deviance - model_omit_1$deviance, \".\\n\")\n",
        "\n",
        "# Show that this differences divided by the Pearson estimate of ϕ is approximately the standardized deviance residuals squared.\n",
        "# model_full\n",
        "cat(\"Deviance divided by dispersion estimate: \", model_full$deviance/phi_est, \".\\n\")\n",
        "cat(\"Sum of standardized deviance residuals squared: \", sum(rstandard(model_full)^2), \".\\n\")\n",
        "\n",
        "# model_omit_1\n",
        "cat(\"Deviance divided by despersion estimate: \", model_omit_1$deviance/(summary(model_omit_1)$dispersion), \".\\n\")\n",
        "cat(\"Sum of standardized deviance residuals squared: \", sum(rstandard(model_omit_1)^2))"
      ],
      "metadata": {
        "id": "1oiFyxcYUlJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "D=\\sum_{i=1}^{n}(r_{i}^{D})^{2}\n",
        "$$\n",
        "\n",
        "$$\n",
        "{r_{i}^{DS}=\\frac{r_{i}^{D}}{\\sqrt{\\hat\\phi(1-h_{ii})}}}\n",
        "$$"
      ],
      "metadata": {
        "id": "c8oemsgxcKU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Repeat the above process for every observation i. \n",
        "# (1) At each iteration, call this model model_omit_i. \n",
        "# (2) Then, compute the difference between the deviance for the full model model_full and for model model_omit_i. \n",
        "# (3) Show that these differences divided by ϕ are approximately the standardized residuals squared.\n",
        "\n",
        "n = nrow(trees)\n",
        "\n",
        "for (i in 1:n) {\n",
        "  # (1)\n",
        "  trees_i = trees[-i,]\n",
        "  model_omit_i = glm( Volume ~ log(Girth) + log(Height),family=Gamma(link=log), data=trees_i)\n",
        "  # (2)\n",
        "  print(model_full$deviance - model_omit_i$deviance)\n",
        "  # (3)\n",
        "  print(model_omit_i$deviance/phi_est - sum(rstandard(model_omit_i)^2))\n",
        "} "
      ],
      "metadata": {
        "id": "CHNbptPncheG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Di9b85oUgOh"
      },
      "source": [
        "# Additional Turn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKkuhJ24UgSx"
      },
      "source": [
        "## Analyse data of car accidents in Sweden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPUN0WhJIQSy"
      },
      "source": [
        "sweden2     <- \"https://raw.githubusercontent.com/francji1/01ZLMA/main/data/sweden.csv\"\n",
        "cars_former <- read.table(sweden2, header = T, sep = \",\")\n",
        "summary(cars_former)\n",
        "head(cars_former)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4eDVhboFv86"
      },
      "source": [
        "Dataset contains the number of deaths, the number of registered cars, the annual volume of sold fuels, the number of registered vehicles and the year. Our goal will be to create the best possible model for death rates. Since these are the number of events per unit time, we use the Poisson distribution with the *canonical link function*  $g (\\mu) = log(\\mu) $.\n",
        "\n",
        "Because the observed period is relatively long and there have been significant changes in transport, we will only consider data from 1975."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row.names(cars) <- NULL\n",
        "cars"
      ],
      "metadata": {
        "id": "u6_qbGMPrd1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig.align": "center",
        "fig.height": 3.5,
        "fig.width": 7,
        "lines_to_next_cell": 2,
        "results": "asis",
        "id": "8YYRVLidFv86"
      },
      "source": [
        "par(mfrow=c(1,2))\n",
        "plot(cars_former$Deaths~cars_former$Year, col=\"red\", lwd=2)\n",
        "cars <- cars_former[cars_former$Year>1974,]\n",
        "plot(cars$Deaths~cars$Year, col=\"red\", lwd=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "remove_output"
        ],
        "id": "WbDYBx7rFv88"
      },
      "source": [
        "#detach(cars)\n",
        "attach(cars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl3o-4bBxrR0"
      },
      "source": [
        "ggpairs(cars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fWNPF2bUgYP"
      },
      "source": [
        "# Tasks \n",
        "\n",
        "* Find the best posssible model. Try adding all variables up to the second order interactions. You can use `step()` function based on `AIC`.\n",
        "* Analyse residuals and check systematic components. \n",
        "* If incorrect linear predictor appears, try to transform corresponding variable. Hint: `Fuel_transformed <- log(abs(Fuel-mean(Fuel)))`\n",
        "* Run post hoc analysis of your final model again\n",
        "* Find influence observations and decide how to cope with them (if any)\n",
        "* Hide last 5 observations, train the model using remaining and try to predict response for the 5 hidden latest observations. Plot predictiions together with true observations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Construction"
      ],
      "metadata": {
        "id": "73GKE5Gd-n2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Full model\n",
        "max_model = glm(Deaths ~ .^3, family=poisson, data=cars)\n",
        "\n",
        "# Null model\n",
        "min_model = glm(Deaths ~ 1, family=poisson, data=cars)"
      ],
      "metadata": {
        "id": "VRsF3zL1YRYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Selection\n",
        "auto.both = step(min_model, direction = \"both\", scope = list(lower = min_model, upper = max_model))"
      ],
      "metadata": {
        "id": "l6vk6hG8mRdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = glm(Deaths ~ Year + Cars + Fuel + Year:Fuel, family=poisson, data=cars)\n",
        "summary(final_model)"
      ],
      "metadata": {
        "id": "x-GRR3womr2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysing Residuals\n",
        "\n",
        "Used to validate \n",
        "* the chosen *link function* (utilizing the working responses) \n",
        "* and the chosen *regressors* (using the Partial Residual Plots).  \n",
        "\n",
        "In PRPs the standardized deviance residuals are used because of their approximately constant variance."
      ],
      "metadata": {
        "id": "Gnmwsxik-8Kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eta = final_model$linear.predictor\n",
        "z   = resid(final_model, type=\"working\") + eta\n",
        "plot(z ~ eta, las=1,\n",
        "        xlab=\"Linear predictor, eta\", ylab=\"Working responses, z\")\n",
        "abline(0, 1, col=\"grey\")"
      ],
      "metadata": {
        "id": "phed2c54G1M2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No trend can be observed from the working responses graph, meaning the data at hand can be properly described with the use of the canonical link function. Therefore no other link function needs to be considered."
      ],
      "metadata": {
        "id": "N-8VjoYbG8mK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_modeled = cars %>%\n",
        "  mutate(fitted = final_model$fitted.values,\n",
        "         r_deviance_std =rstandard(final_model, type = \"deviance\"),\n",
        "         r_pearson_std = rstandard(final_model, type = \"pearson\") )\n",
        "head(cars_modeled)"
      ],
      "metadata": {
        "id": "Za7bSPbi6iPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ggplot(cars_modeled, aes(x = Deaths, y = fitted)) + \n",
        "  geom_smooth()+\n",
        "  geom_point() +\n",
        "  geom_abline(intercept = 0, slope = 1)"
      ],
      "metadata": {
        "id": "8xZmxKQo611S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ggplot(cars_modeled, aes(x = fitted, y = r_deviance_std)) +\n",
        "  geom_smooth() +\n",
        "  geom_point() +\n",
        "  labs(x = \"Fitted values\",\n",
        "       y = \"Deviance standardized residuals\")"
      ],
      "metadata": {
        "id": "6LAGes2b8unp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ggplot(cars_modeled, aes(x = Year, y = r_deviance_std)) +\n",
        "  geom_smooth() +\n",
        "  geom_point() +\n",
        "  labs(x = \"Predictor variable: Year\",\n",
        "       y = \"Deviance standardized residuals\")"
      ],
      "metadata": {
        "id": "rDWaamGZMc6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ggplot(cars_modeled, aes(x = Cars, y = r_deviance_std)) +\n",
        "  geom_smooth() +\n",
        "  geom_point() +\n",
        "  labs(x = \"Predictor variable: Cars\",\n",
        "       y = \"Deviance standardized residuals\")"
      ],
      "metadata": {
        "id": "sw9FgjOZ9EsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ggplot(cars_modeled, aes(x = Fuel, y = r_deviance_std)) +\n",
        "  geom_smooth() +\n",
        "  geom_point() +\n",
        "  labs(x = \"Predictor variable: Fuel\",\n",
        "       y = \"Deviance standardized residuals\")"
      ],
      "metadata": {
        "id": "I3Vqg63N9rvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ggplot(cars_modeled, aes(x = Fuel*Year, y = r_deviance_std)) +\n",
        "  geom_smooth() +\n",
        "  geom_point() +\n",
        "  labs(x = \"Predictor variable: Fuel*Year\",\n",
        "       y = \"Deviance standardized residuals\")"
      ],
      "metadata": {
        "id": "K9sFQOPOI_VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transforming the Problematic Regressors\n",
        "The residuals in the last two plots of the previous section are not scattered evenly around zero. On the contrary, a visible crook can be seen in the centre of the graph. \n",
        "\n",
        "This means that the relationship between the regressor `Fuel` and the dependent variable `Deaths` is not linear and needs to be transformed. For this purpose the transformation hinted on in the task of the assignment, i.e. `Fuel_transformed = log(abs(Fuel-mean(Fuel)))` will be used."
      ],
      "metadata": {
        "id": "c9wNnL6A_Rz8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-29O7iFdrNF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Fuel_transformed = log(abs(Fuel-mean(Fuel)))\n",
        "\n",
        "transformed_model = glm(Deaths ~ Year + Cars + Fuel_transformed + Year:Fuel, family=poisson, data=cars)\n",
        "summary(transformed_model)"
      ],
      "metadata": {
        "id": "w8Pdsl-_-PkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cars_modeled_new = cars %>%\n",
        "  mutate(fitted = transformed_model$fitted.values,\n",
        "         Fuel_transformed = log(abs(Fuel-mean(Fuel))),\n",
        "         r_deviance_std =rstandard(transformed_model, type = \"deviance\"),\n",
        "         r_pearson_std = rstandard(transformed_model, type = \"pearson\") )\n",
        "head(cars_modeled_new)"
      ],
      "metadata": {
        "id": "r8KlG7c6NNgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cars_modeled_new = cars_modeled_new %>%\n",
        "mutate(Partial_for_Year = as.data.frame(resid(transformed_model, type=\"partial\"))$Year,\n",
        "        Partial_for_Fuel = as.data.frame(resid(transformed_model, type=\"partial\"))$Fuel_transformed,\n",
        "        Partial_for_Cars = as.data.frame(resid(transformed_model, type=\"partial\"))$Cars)"
      ],
      "metadata": {
        "id": "HysnUDHnNUCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ggplot(cars_modeled_new, aes(x = Fuel_transformed, y = r_deviance_std)) +\n",
        "  geom_smooth() +\n",
        "  geom_point() +\n",
        "  labs(x = \"Predictor variable: Fuel_transformed\",\n",
        "       y = \"Deviance standardized residuals\")"
      ],
      "metadata": {
        "id": "k1n2DAHQAeV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ggplot(cars_modeled_new, aes(x = Fuel_transformed*Year, y = r_deviance_std)) +\n",
        "  geom_smooth() +\n",
        "  geom_point() +\n",
        "  labs(x = \"Predictor variable: Fuel_transformed*Year\",\n",
        "       y = \"Deviance standardized residuals\")"
      ],
      "metadata": {
        "id": "Et6xsGuZJQkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identifying Influential Observations"
      ],
      "metadata": {
        "id": "BFQxVAL-PYPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "im = influence.measures(transformed_model)\n",
        "names(im)\n",
        "\n",
        "colSums(im$is.inf)"
      ],
      "metadata": {
        "id": "BCJ41y9vY1F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rownames(summary(im))"
      ],
      "metadata": {
        "id": "G6kY5Aa5sDwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(im)\n",
        "infl = as.numeric(rownames(summary(im)))"
      ],
      "metadata": {
        "id": "EN6yc8IBqUzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KJZzegYRsA9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd = cooks.distance(transformed_model)\n",
        "plot(cd)\n",
        "\n",
        "# Rule of thumb:\n",
        "n = nrow(cars)  # number of observations\n",
        "p = 5           # number of parameters\n",
        "influential = 8/(n - 2*p)\n",
        "cd[cd > influential]"
      ],
      "metadata": {
        "id": "lfovjgioZDH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two influential observations have been found based on Cook's distance. A new model is trained on data which do not include the rows identified as influential to demonstrate the effect these observations have on the coefficients estimation. "
      ],
      "metadata": {
        "id": "Ez4wHmp5QXoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "infl_model = update(transformed_model, subset=(-infl))\n",
        "\n",
        "coef(transformed_model)\n",
        "coef(infl_model)"
      ],
      "metadata": {
        "id": "Om8R6-i-Z7kT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd2 = cooks.distance(infl_model)\n",
        "plot(cd2)"
      ],
      "metadata": {
        "id": "-t2CE8XArEP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(infl_model)"
      ],
      "metadata": {
        "id": "iIuDkw7fZ-xE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since both of the identified observations come from the end of the data frame (observations 33 and 36 out of 36 observations) and can therofore be considered boundary observations, it is not reliable to base the estimations of the model parameters on these values. The lowered number of deaths in the year 2007 and later on could have been caused by a further modernization of the automobile industry or possibly a lower demand based on the ongoing Great Recession. That is why we choose to continue the analysis with the updated model trained of the data without the said observations. "
      ],
      "metadata": {
        "id": "Citl2KmQUqcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "i37jy2UJXRvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "omit_5 = c(32, 33, 34, 35, 36)\n",
        "\n",
        "model_omit_5 = update(infl_model, subset=(-omit_5))\n",
        "\n",
        "cars_predict = cars%>%\n",
        "  mutate(Fuel_transformed = log(abs(Fuel-mean(Fuel))))"
      ],
      "metadata": {
        "id": "bNq7hSokwm7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_deaths = predict(model_omit_5, newdata = cars_predict[omit_5, ])\n",
        "predicted_deaths"
      ],
      "metadata": {
        "id": "PIv4q90uyvy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cars$Deaths[omit_5]"
      ],
      "metadata": {
        "id": "79-ksT6H5kr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(cars$Deaths ~ cars$Year, col=\"red\", cex=0.9, lwd=1.5, \n",
        "     xlab = \"Year\", ylab=\"Deaths\", las=1)\n",
        "legend(\"topright\", inset = .05, legend = c(\"Data\", \"Model\"), \n",
        "       col = c(\"red\", \"blue\"), bty=\"n\", lwd = 1.5, pch=c(1,1), cex=0.9, lty=c(NA,NA))\n",
        "points(fitted(model_omit_5) ~ cars$Year[-omit_5], col=\"blue\", lwd=1.5)\n",
        "points(predicted_deaths ~ cars_predict$Year[omit_5], col=\"blue\", lwd=1.5)"
      ],
      "metadata": {
        "id": "-e3-Svio6jfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(cars$Deaths ~ cars$Cars, col=\"red\", cex=0.9, lwd=1.5, \n",
        "     xlab = \"Cars\", ylab=\"Deaths\", las=1)\n",
        "legend(\"topright\", inset = .05, legend = c(\"Data\", \"Model\"), \n",
        "       col = c(\"red\", \"blue\"), bty=\"n\", lwd = 1.5, pch=c(1,1), cex=0.9, lty=c(NA,NA))\n",
        "points(fitted(model_omit_5) ~ cars$Cars[-omit_5], col=\"blue\", lwd=1.5)\n",
        "points(predicted_deaths ~ cars_predict$Cars[omit_5], col=\"blue\", lwd=1.5)"
      ],
      "metadata": {
        "id": "Q4GbSRnD9oL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(cars$Deaths ~ cars$Fuel, col=\"red\", cex=0.9, lwd=1.5, \n",
        "     xlab = \"Fuel\", ylab=\"Deaths\", las=1)\n",
        "legend(\"topright\", inset = .05, legend = c(\"Data\", \"Model\"), \n",
        "       col = c(\"red\", \"blue\"), bty=\"n\", lwd = 1.5, pch=c(1,1), cex=0.9, lty=c(NA,NA))\n",
        "points(predicted_deaths ~ cars_predict$Fuel[omit_5], col=\"blue\", lwd=1.5)\n",
        "points(fitted(model_omit_5) ~ cars$Fuel[-omit_5], col=\"blue\", lwd=1.5)"
      ],
      "metadata": {
        "id": "X2Wa2GUB_vzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8T091z8wFk6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}